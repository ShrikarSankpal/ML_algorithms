{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "#TFIDF - Term Frequency and Inverse Document Frequency\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# for sequential execution of functions\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target names: \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "target: \n",
      " [7 4 4 ... 3 1 8]\n"
     ]
    }
   ],
   "source": [
    "X , y = fetch_20newsgroups(return_X_y=True)\n",
    "data = fetch_20newsgroups()\n",
    "print(\"target names: \\n\",data.target_names)\n",
    "print(\"target: \\n\",data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select a small subset outta targets for model\n",
    "* we did this becase we wanna reduce calculations and we are lazy\n",
    "\n",
    "* ideally, you should take all targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "2379\n"
     ]
    }
   ],
   "source": [
    "topics = ['comp.graphics', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "newsgrpdata = fetch_20newsgroups(categories=topics)\n",
    "print(type(newsgrpdata))\n",
    "print(len(newsgrpdata.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see how data looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: mbeaving@bnr.ca (Michael Beavington)\n",
      "Subject: Re: Ok, So I was a little hasty...\n",
      "Nntp-Posting-Host: bmerh824\n",
      "Reply-To: MBEAVING@BNR.CA\n",
      "Organization: BNR Ottawa, DMS Software Design\n",
      "Lines: 18\n",
      "\n",
      "In article <13394@news.duke.edu>, infante@acpub.duke.edu (Andrew  Infante) writes:\n",
      "|> Apparently that last post was a little hasy, since I\n",
      "|> called around to more places and got quotes for less\n",
      "|> than 600 and 425.  Liability only, of course.\n",
      "|> \n",
      "|> Plus, one palced will give me C7C for my car + liab on the bike for\n",
      "|> only 1350 total, which ain't bad at all.\n",
      "|> \n",
      "|> So I won't go with the first place I called, that's\n",
      "|> fer sure.\n",
      "|> \n",
      "\n",
      "Nevertheless, DWI is F*ckin serious.  Hope you've got some \n",
      "brains now.\n",
      "\n",
      "Mike Beavington\n",
      "mbeaving@bnr.ca\n",
      "* these opinions are my own and not my companies'.\n",
      "\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(newsgrpdata.data[0])\n",
    "print(newsgrpdata.target_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model and fit\n",
    "\n",
    "* things in pipeline go one after another\n",
    "\n",
    "* what does tfidf do?\n",
    " * Convert a collection of raw documents to a matrix of TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbmodel = make_pipeline(TfidfVectorizer(),MultinomialNB())\n",
    "mnbmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 15 15 ...  0  2  5]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mnbmodel.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8291605301914581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82       141\n",
      "           1       0.87      0.73      0.79       171\n",
      "           2       0.86      0.86      0.86       170\n",
      "           3       0.77      0.78      0.78       178\n",
      "           4       0.88      0.87      0.87       165\n",
      "           5       0.92      0.87      0.90       184\n",
      "           6       0.88      0.57      0.69       185\n",
      "           7       0.82      0.89      0.85       173\n",
      "           8       0.89      0.97      0.93       161\n",
      "           9       0.90      0.94      0.92       166\n",
      "          10       0.87      0.99      0.93       163\n",
      "          11       0.69      0.99      0.81       177\n",
      "          12       0.93      0.68      0.79       189\n",
      "          13       0.97      0.90      0.94       177\n",
      "          14       0.90      0.95      0.92       180\n",
      "          15       0.54      0.98      0.70       185\n",
      "          16       0.74      0.96      0.83       166\n",
      "          17       0.95      0.96      0.96       187\n",
      "          18       1.00      0.57      0.73       157\n",
      "          19       0.94      0.13      0.23       120\n",
      "\n",
      "    accuracy                           0.83      3395\n",
      "   macro avg       0.86      0.82      0.81      3395\n",
      "weighted avg       0.86      0.83      0.82      3395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtest[0]: \n",
      " From: johnsw@wsuvm1.csc.wsu.edu (William E. Johns)\n",
      "Subject: Need a wheel\n",
      "Originator: bill@wsuaix.csc.wsu.edu\n",
      "Keywords: '92\n",
      "Organization: Washington State University\n",
      "Distribution: na\n",
      "Lines: 18\n",
      "\n",
      "\n",
      "Does anyone have a rear wheel for a PD they'd like to part with?\n",
      "\n",
      "Does anyone know where I might find one salvage?\n",
      "\n",
      "As long as I'm getting the GIVI luggage for Brunnhilde and have\n",
      "the room, I thought I'd carry a spare.\n",
      "\n",
      "Ride Free,\n",
      "\n",
      "Bill\n",
      "___________________________________________________________________             \n",
      "johnsw@wsuvm1.csc.wsu.edu  prez=BIMC  KotV KotRR                                \n",
      "DoD #00314  AMA #580924   SPI = 7.18   WMTC #0002  KotD #0001             \n",
      "Yamabeemer fj100gs1200pdr650 Special and a Volvo.  What more could anyone ask? \n",
      "                                                           \n",
      "Pain is inevitable, suffering is optional.\n",
      " \n",
      "\n",
      "ytest[0]: \n",
      " 8 rec.motorcycles\n",
      "ypred[0]: \n",
      " 8 rec.motorcycles\n"
     ]
    }
   ],
   "source": [
    "print(\"Xtest[0]: \\n\",X_test[0])\n",
    "print(\"ytest[0]: \\n\",y_test[0], data.target_names[y_test[0]])\n",
    "print(\"ypred[0]: \\n\",y_pred[0], data.target_names[y_pred[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test on a random self made document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "message = \"\"\"sorry sir I missed few points about bike can you repeat once sir like mode of words means it splits according to mode of words and sort according to frequency\n",
    "\"\"\"\n",
    "pred = mnbmodel.predict([message])\n",
    "print(pred[0],data.target_names[pred[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
